import torch
from torch import nn
import numpy as np
from net.prune import PruningModule,MaskedLinear

device = torch.device("cuda" if torch.cuda.is_available() else 'cpu')

class np_LSTM(PruningModule):
    r'LSTM with embedding layer; for human predict'

    def __init__(self, input_size, hidden_size,batch_size, num_layers,dropout, mask=True):
        super(np_LSTM, self).__init__()
        linear = MaskedLinear if mask else nn.Linear
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.batch_size = batch_size
        self.num_layers = num_layers
        self.gate = linear(input_size + hidden_size, hidden_size)
        self.output = linear(hidden_size, input_size)
        self.sigmoid = nn.Sigmoid()
        self.tanh = nn.Tanh()
        self.dropout = nn.Dropout(p=dropout)
        # nn.LogSoftmax()
        self.softmax = nn.Softmax()

    def forward(self, input):
        max_time = input.size(0)
        batch_size = input.size(1)
        hidden = self.initHidden(batch_size)
        cell = self.initCell(batch_size)
        for layer in range(self.num_layers):
            for time in range(max_time):
                input_slice = input[time]
                # output = torch.stack(output, 0)
                combined = torch.cat((hidden.float(), input_slice.float()), 1)
                f_gate = self.gate(combined)
                i_gate = self.gate(combined)
                o_gate = self.gate(combined)
                f_gate = self.sigmoid(f_gate)
                i_gate = self.sigmoid(i_gate)
                o_gate = self.sigmoid(o_gate)
                cell_helper = self.gate(combined)
                cell_helper = self.tanh(cell_helper)
                cell = torch.add(torch.mul(cell.float(), f_gate.float()),
                                 torch.mul(cell_helper.float(), i_gate.float()))
                hidden = torch.mul(self.tanh(cell), o_gate)
                # for multi-layer LSTMs
                output = self.output(hidden)
        return output

    def initHidden(self,batch_size):
        return torch.zeros(batch_size, self.hidden_size).to(device)

    def initCell(self,batch_size):
        return torch.zeros(batch_size, self.hidden_size).to(device)

